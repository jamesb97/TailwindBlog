---
title: Autonomous Vehicles
date: '2021-02-10'
tags: ['EVs', 'Autonomous', 'iot', 'AI']
draft: false
summary: Autonomous Vehicles are certain types of vehicles that are capable of performing similar actions compared to humans in operating driverless technology through the ability to sense it's nearby surroundings.
---

# Autonomous Vehicles

      <Image src="https://firebasestorage.googleapis.com/v0/b/techblog-e0db2.appspot.com/o/1703186075988.jpeg?alt=media&token=0c9aee46-1e73-46e7-bf9d-076cefe7da01" width={800} height={150} alt="Tesla" />

Autonomous Vehicles are certain types of vehicles that are capable of performing similar actions
compared to humans in operating driverless technology through the ability to sense it's nearby
surroundings. These vehicles are equipped with multiple sensors, lidar, and radar detection
optimization, and scene optimization to name a few. Autonomous vehicles technology involves multiple
key components when it comes to the proper interaction of an autonomous vehicle. The technology
behind autonomous vehicles integration consists of sensors, connectivity, and software controlled
algorithms that power the seamless autonomy. Each component plays a big role in allocating an
automated vehicle that is able to successfully be on the road.

Some examples of Autonomous Vehicles include:

- Tesla Model S
- Cadillac CT6
- Mercedes-Benz S-Class
- BMW X7

#### The Concept

Self-driving cars, also referred to as autonomous cars or driverless cars, obtains visual information from a series of cameras and sensors, converts it to grayscale, and applies semantic segmentation using AI technology. This then gets the system to process any ongoing changes being interpreted during the driving simulation.

The 6 different levels of autonomy:

Level 0: A human driver has total control over all the operations.

Level 1: A function is automated.

Level 2: More than one function becomes automated, whether that is the steering wheel and acceleration.

Level 3: Conditional Automation, capable of performing some tasks.

Level 4: High Automation, able to perform most tasks.

Level 5: Fully autonomous in which the vehicle is capable of self operating.

"To qualify as fully autonomous, a vehicle must be able to navigate without a human intervention to a predetermined destination over roads that have not been adapted for its use.

#### Details

Developers behind the autonomous self-driving technologies imply an ample quantity of data including image recognition systems, machine learning and neural networks in order to successfully design an autonomous self-driving experience. The neural networks are responsible for identifying the interpreted data collection patterns by implying machine learning gathered from the camera's visual interpretation of it's surrounding environment. Drive OS, offered by Nvidia, is an operating system designed for accelerated computing that offers multiple input sensors processing real-time AI inference. It is crucial in providing input information for autonomous vehicles. It consists of the sensor abstraction layer(SAL), vehicle I/O support and a deep neural network(DNN) framework.

<b>Challenges/Concerns</b>: In March 2018, Elaine Herzberg died after a self-driving Uber Volvo car
failed to recognize the object from its camera sensors as a pedestrian in Arizona.

<b>What should be the next steps?</b> More testing that yields better results in classifying each
tertiary object within the camera's sensor point-of-view. Fewer error prone logs.

<b>Google's self driving project(Waymo)</b>: Waymo utilizes a mixture of sensors including Lidar and
consolidates deep learning algorithms with Google Maps.

#### Lidar Technology

<b>Concept</b>: Lidar(Light detection and ranging) technology is one of the most popular remote
sensing approaches when it comes to calculating an object's exact distance located on Earth's
surface. Lidar implies a pulsed radar that is used to measure the object's variable distance by
emitting light pulses. These light pulses are capable of generating accurate 3D information from the
Earth's surface and its target object. There are three primary components when it comes to Lidar
systems: the scanner, laser, and GPS receiver.

Examples of Lidar Systems being used in production today include Airborne Lidar, and Terrestrial Lidar.

<b>Fundamental</b>: Shine a laser light onto a terrestrial object, and calculate the amount of time
required to return its source.

<b>Formula</b>: Distance of the object = (Speed of Light x Time of Flight) / 2.

<b>Developmental Aspirations</b>: Oceanography, Digital Elevation or Terrain Model, Agriculture &
Archaeology.

Lidar technologies have been rapidly expanding in production, reaching an all time high for consumer demands since 2016 and beyond. Fully autonomous vehicles are expected to hit the market as early as 2027.

<Image
  src="https://firebasestorage.googleapis.com/v0/b/techblog-e0db2.appspot.com/o/lidar_xlpnll.jpg?alt=media&token=b12284a4-3966-44c7-9c5d-b6db1bc2b23e"
  alt="lidar"
  width={550}
  height={250}
/>
<figcaption>Figure 1. Lidar instantaneous velocity measurement.</figcaption>
<br />

<b>Steps needed to obtain a fully autonomous projection system</b>:

Sense: Gather environment information from sensors.

Perceive: Filter, interpret & understand sensor data.

Decide: Safely choose actions.

Actuate: Initiate actions.

<b>Challenges</b>: The price for autonomous vehicle protection is relatively expensive. The increase
of sensor proximity and real-time detection is becoming more challenging with newer innovations and
time optimization. Increase in software complexity. Enlightened in-car passenger exposures.

#### Automakers adopting autonomous technology

| Autonomous Technology           | Tesla | BMW | Comments/Concerns                                                                                                                                                                              |
| ------------------------------- | ----- | --- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1. Multiple Camera Integration  | Yes   | Yes | Both companies imply the use of interpreting multiple cameras being installed on different areas of each vehicle for providing a better visual representation in its surrounding environment.  |
| 2. Sensor Manipulation          | Yes   | Yes | BMW agrees that it will use it's sensors to better help determine a precise location for surrounding vehicles in order to determine if it is acceptable to changes lanes during its operation. |
| 3. Ultrasonic sensors and Lidar | No    | Yes | Tesla's CEO Elon Musk has said that the adoption of Lidar technologies is fairly expensive and the technology is difficult to mass-produce for consumer vehicles.                              |

#### Future

Automakers are expected to further integrate multiple AI technologies and neural networks into their systems with the adaptation of computer vision along with software and hardware enhancements such as deep learning algorithms, image recognition and convolutional neural networks.

#### Autonomous Vehicle Job Market Share 2019

| Rank | Company                | Job Openings(%) |
| ---- | ---------------------- | --------------- |
| 1    | Aptiv                  | 21.7            |
| 2    | Nvidia                 | 5.0             |
| 3    | SAIC Innovation Center | 4.8             |
| 4    | Bosh                   | 4.3             |
| 5    | Daimler AG             | 3.4             |
| 6    | Cruise Automation      | 3.3             |
| 7    | General Motors         | 2.5             |

#### Conclusion

It is expected that by the end of 2020, automaker manufacturers will deploy multiple vehicles with integrated semi-fully autonomous features. And by the year 2035, it is expected that most cars will be able to gain full autonomy.
